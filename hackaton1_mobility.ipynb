{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6258f787-8238-4d9f-a7b6-5f66b8e7a1ca",
   "metadata": {},
   "source": [
    "# Hackaton project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd9f3b9-a619-4019-a0ee-c5adf3c1b8fe",
   "metadata": {},
   "source": [
    "Идея проекта - оповещать персонал мед клиники о местонахождении маломобильного человека. \n",
    "\n",
    "Датасет взят из открытых источников, с сайта https://universe.roboflow.com/\n",
    "\n",
    "Модель распознавания - YOLO 8 версия\n",
    "\n",
    "Для оповещения сделан бот в телеграме, изначально он закомментирован (последняя строка), раскомментируйте его, потом запускайте код."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded254e8-4688-4b61-b087-bb8b92d958aa",
   "metadata": {},
   "source": [
    "## Грузим необходимые библиотеки и зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6494a4d3-bc83-4d8c-b5a7-9fb9b0121c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in d:\\anaconda\\lib\\site-packages (8.3.51)\n",
      "Requirement already satisfied: numpy>=1.23.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\anaconda\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\anaconda\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in d:\\anaconda\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\anaconda\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in d:\\anaconda\\lib\\site-packages (from ultralytics) (2.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\anaconda\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ce6659-9c66-4b19-9c8f-78e73248c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff3a1d0-7aa7-4e77-97af-f5baaeccf7b0",
   "metadata": {},
   "source": [
    "### Загружаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b9de78-5621-4efd-9aef-853c7925503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8dc403c-d9b6-4b5e-8420-2af766335321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f0a0e-2e66-4110-990c-95881ba88e23",
   "metadata": {},
   "source": [
    "### Обучаем модель\n",
    "\n",
    "Сделано 10 эпох и оптимизатор - стохастический градиентный спуск (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f247228-ee9e-44e4-a9e8-7ee6b3995da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.51  Python-3.12.4 torch-2.5.1+cpu CPU (AMD Ryzen 5 5600H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=datasets/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train5\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train5', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\kat_y\\Documents\\Python projects (clouds edition)\\MIPT\\hackaton\\datasets\\train\\labels.cache... \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\kat_y\\Documents\\Python projects (clouds edition)\\MIPT\\hackaton\\datasets\\valid\\labels.cache... 76\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train5\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/data.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSGD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\engine\\model.py:806\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 806\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:380\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[0;32m    379\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch)\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:111\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:292\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[1;34m(self, batch, preds)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[1;32m--> 292\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:347\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:50\u001b[0m, in \u001b[0;36mConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)))\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(data = 'datasets/data.yaml', epochs = 10, optimizer = 'SGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1ac18-dfc5-47a5-bcea-431a605008e6",
   "metadata": {},
   "source": [
    "## Тестируем модель на новых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff95b0-3fa8-4efc-945a-fd9daa25e6a4",
   "metadata": {},
   "source": [
    "Грузим новую модель, лучшую из всех, которые были получены на предыдущем этапе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41a062e7-37c3-48a6-8306-9af9c8e3e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = YOLO('../runs/detect/train42/weights/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97364f2-6e66-458f-ab7e-0ded7533f83a",
   "metadata": {},
   "source": [
    "Грузим картинки из папки, делаем предсказание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5968cd23-6f49-47ec-8e16-b9a30a219bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружена картинка: 001675b1bb8d54ed_jpg.rf.c51966d1a9f74710b62979c0262c0135.jpg\n",
      "\n",
      "0: 640x640 1 Wheelchair, 281.1ms\n",
      "Speed: 5.1ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 001675b1bb8d54ed_jpg.rf.f0e904cbc862a21776b9c501fa20a49b.jpg\n",
      "\n",
      "0: 640x640 (no detections), 270.3ms\n",
      "Speed: 0.0ms preprocess, 270.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 008b6a82d34b59c5-Copy_jpg.rf.94c77ba9c6b915e69ec4705d8639acd9.jpg\n",
      "\n",
      "0: 640x640 3 Wheelchairs, 276.3ms\n",
      "Speed: 1.9ms preprocess, 276.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 023dac604c016ac3-Copy_jpg.rf.3f61dd7b150550c8462a3caf2d82837a.jpg\n",
      "\n",
      "0: 640x640 1 Wheelchair, 283.1ms\n",
      "Speed: 2.2ms preprocess, 283.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 024cd3c930845976-Copy_jpg.rf.259c8254f15868a8f2f2af1659a0d49b.jpg\n",
      "\n",
      "0: 640x640 (no detections), 272.7ms\n",
      "Speed: 2.0ms preprocess, 272.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 0290a83dc809cab7_jpg.rf.59d41d37ba29671ddda9a48803f987f9.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 1 Wheelchair, 284.9ms\n",
      "Speed: 2.2ms preprocess, 284.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 03b1b8c5eface6b6-Copy_jpg.rf.11d1febee0327f5794d9f641af119068.jpg\n",
      "\n",
      "0: 640x640 (no detections), 294.9ms\n",
      "Speed: 0.0ms preprocess, 294.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 03b1b8c5eface6b6-Copy_jpg.rf.7a99c58e568ff039f97629b8e8b6148e.jpg\n",
      "\n",
      "0: 640x640 1 Wheelchair, 283.4ms\n",
      "Speed: 2.3ms preprocess, 283.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 0499d22dc8ada2e7_jpg.rf.2db2bc1680fc2264c0502dd5ffa27745.jpg\n",
      "\n",
      "0: 640x640 (no detections), 291.6ms\n",
      "Speed: 2.6ms preprocess, 291.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 04b029cff6db3b5b-Copy_jpg.rf.e832181983a4a904aa45dcbd18cee7b4.jpg\n",
      "\n",
      "0: 640x640 2 Wheelchairs, 295.5ms\n",
      "Speed: 3.1ms preprocess, 295.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 05408142adaa4a71_jpg.rf.5aaadee8e16ac250a40e613693aef286.jpg\n",
      "\n",
      "0: 640x640 1 Wheelchair, 296.0ms\n",
      "Speed: 0.0ms preprocess, 296.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 05bab3fd8b805069-Copy_jpg.rf.1d44657e137ca20a93bed2c499bb9837.jpg\n",
      "\n",
      "0: 640x640 2 Wheelchairs, 280.2ms\n",
      "Speed: 2.1ms preprocess, 280.2ms inference, 12.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 060055f5202ecc2b_jpg.rf.4c109c55d76d5f0e05800f427139f64b.jpg\n",
      "\n",
      "0: 640x640 2 Wheelchairs, 299.3ms\n",
      "Speed: 0.0ms preprocess, 299.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 080428641eb6e2ad_jpg.rf.da93c2f99311df06427292a00e925751.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 1 Wheelchair, 290.4ms\n",
      "Speed: 2.2ms preprocess, 290.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 10500d1023bdbb1a_jpg.rf.d40d813328f5a7c6a7ea3f26d9090e80.jpg\n",
      "\n",
      "0: 640x640 4 Canes, 289.7ms\n",
      "Speed: 2.0ms preprocess, 289.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 1239019017_0_jpg.rf.1231b1eca8660ecfb7e4cc1a8cf82ea3.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 270.4ms\n",
      "Speed: 2.0ms preprocess, 270.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 1274352005_0_jpg.rf.a2c189a4e8151c404cb9af4638d0c8a1.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 284.2ms\n",
      "Speed: 21.0ms preprocess, 284.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 138d5b7eccce3138fb1ec84612c04dfa3575011566050881_jpg.rf.56fc98ce4562db51d8e4421b472049d0.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 267.5ms\n",
      "Speed: 4.4ms preprocess, 267.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 15057314069054186_jpg.rf.26f68dadc36b197814016838d8e34a9d.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 267.1ms\n",
      "Speed: 1.7ms preprocess, 267.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 1965dc20bdc31298_jpg.rf.86c8ce72113d547300eaa380b38a497a.jpg\n",
      "\n",
      "0: 640x640 1 Wheelchair, 275.9ms\n",
      "Speed: 0.0ms preprocess, 275.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 196a6c21695db37d_jpg.rf.037a8522bcba077fba2f0c25cd75e4f1.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 268.9ms\n",
      "Speed: 5.1ms preprocess, 268.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 29029326485_920f11a4ca_b_jpg.rf.09ea0880b9477e799bb56584eec9a961.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 269.1ms\n",
      "Speed: 0.0ms preprocess, 269.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 35_jpg.rf.b8d8ff0d06dd836525ddc594aacea1ce.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 277.5ms\n",
      "Speed: 0.0ms preprocess, 277.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 360_F_160280085_YIUw1SRMQ6dELR79ToAHfwdHuTdWG0hf_jpg.rf.8a32c150386ec63d237cf4825438b702.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 296.2ms\n",
      "Speed: 0.0ms preprocess, 296.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 371c708ae5c4f9d1_jpg.rf.f442810de98954d07c8ace27827f818e.jpg\n",
      "\n",
      "0: 640x640 3 Canes, 264.9ms\n",
      "Speed: 1.9ms preprocess, 264.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 3AD2CDBC00000578-0-image-a-41_1480340645784_jpg.rf.bd2cb3a8fdb6d93faac87e6fbf73b4c3.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 270.8ms\n",
      "Speed: 2.7ms preprocess, 270.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 3F28B8BF00000578-4401680-image-a-85_1491919164334_jpg.rf.b8b01b60582acc0b0c6461f7f4cf4f33.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 264.7ms\n",
      "Speed: 2.4ms preprocess, 264.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 3f69d076b31fa1e6_jpg.rf.b24b0b2d89a34623c5fc8911f8591691.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 266.1ms\n",
      "Speed: 0.0ms preprocess, 266.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 4133c7e8a60b48fa74b6a0c70800c5a7_jpg.rf.d2af3c819a8a085db944ad5171399170.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 264.3ms\n",
      "Speed: 0.0ms preprocess, 264.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 43252717-9602793-image-a-50_1621557808213_jpg.rf.1125f1a0ce3eab610207ca22da8a1915.jpg\n",
      "\n",
      "0: 640x640 5 Canes, 276.5ms\n",
      "Speed: 0.0ms preprocess, 276.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 6305_jpeg_jpg.rf.df024808083aafcd8c3aa9d6b7f8cac9.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 276.2ms\n",
      "Speed: 2.0ms preprocess, 276.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: 6d94a2fb_jpg.rf.0dacc270217f0695370e608445d483d7.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 279.0ms\n",
      "Speed: 0.0ms preprocess, 279.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: fe8c69c0af6ac00b_jpg.rf.a52952b5faf76a4840248f84ea16800d.jpg\n",
      "\n",
      "0: 640x640 2 Wheelchairs, 268.3ms\n",
      "Speed: 2.1ms preprocess, 268.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: ff507e0c5765fea6_jpg.rf.afc1bafed64672eeef10f4446f0184e1.jpg\n",
      "\n",
      "0: 640x640 (no detections), 285.6ms\n",
      "Speed: 1.2ms preprocess, 285.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: laufen-kr_cken_png_jpg.rf.58cd6fa308377098d5815ec335dbc105.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 285.1ms\n",
      "Speed: 2.3ms preprocess, 285.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: NcCMhmF1Pt_jpeg_jpg.rf.1f9abf596cb5a518a24da70b1a714356.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 276.3ms\n",
      "Speed: 2.2ms preprocess, 276.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: nHOdyNfblW_jpeg_jpg.rf.d7f21b0497ba4ff8a950bc957490a097.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 296.6ms\n",
      "Speed: 19.9ms preprocess, 296.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: no2_png_jpg.rf.a3f9b6795f509b81b0ac3f4e19c60644.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 271.1ms\n",
      "Speed: 1.2ms preprocess, 271.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: pakryckor_jpg.rf.012ccf7cebe44906cf62059465553739.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 273.2ms\n",
      "Speed: 0.0ms preprocess, 273.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: pl1_jpeg_jpg.rf.6babf548e66510daf90369da8d8beec6.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 277.8ms\n",
      "Speed: 0.0ms preprocess, 277.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: pl3_jpeg_jpg.rf.38df105157d12e860d6d88b6a2d31829.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 295.4ms\n",
      "Speed: 0.0ms preprocess, 295.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: ryMUZilk5r_jpeg_jpg.rf.ff1087e9c71bccc25c7f903a94d25757.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 285.9ms\n",
      "Speed: 0.0ms preprocess, 285.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: Shutterstock_5952210a_jpg.rf.ad1151af268893a887edf5fa4181260e.jpg\n",
      "\n",
      "0: 640x640 3 Canes, 281.4ms\n",
      "Speed: 1.5ms preprocess, 281.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: tamzin-outhwaite-leaves-the-itv-studios-on-crutches-after-fracturing-HYTAY9_jpg.rf.149d415959963d893bb6059b8c1219a3.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 269.0ms\n",
      "Speed: 3.0ms preprocess, 269.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: Triathlove-Triathlon-Blog-Sportverletzung-Banderriss-Absage-Zillertal-Bike-Challenge_jpg.rf.6d4e3892cbdeb60cddd39e3a3a56dfdf.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 284.4ms\n",
      "Speed: 1.2ms preprocess, 284.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: vue-arriere-d-un-homme-marchant-sur-la-rue-avec-des-bequilles-jye128_jpg.rf.c22b13a09c8acdd503710a97d1677767.jpg\n",
      "\n",
      "0: 640x640 1 Cane, 280.8ms\n",
      "Speed: 0.6ms preprocess, 280.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: vzEhNT7tXM_jpeg_jpg.rf.1f32dc3bae4efeeb9193b67fd6ce3fca.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 266.3ms\n",
      "Speed: 15.7ms preprocess, 266.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: Wags-and-Players-At-Old-Trafford_jpg.rf.db6ad425f08e43bfb67da1ce3ef7c36b.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 278.1ms\n",
      "Speed: 0.0ms preprocess, 278.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "Загружена картинка: ZPw5pxAOB9_jpeg_jpg.rf.562fcd87c5e473b02dc330ea5ee0cd84.jpg\n",
      "\n",
      "0: 640x640 2 Canes, 266.8ms\n",
      "Speed: 3.0ms preprocess, 266.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Укажите путь к папке с картинками\n",
    "image_folder = 'datasets/test/images'\n",
    "\n",
    "# Получаем список файлов в папке\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Итерируемся по файлам и загружаем картинки\n",
    "for image_file in image_files:\n",
    "    # Формируем полный путь к файлу\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    # Загружаем картинку\n",
    "    image = Image.open(image_path)\n",
    "    # Теперь вы можете работать с загруженной картинкой\n",
    "    print(f'Загружена картинка: {image_file}')\n",
    "    # Делаем предсказание для каждой картинки\n",
    "    new_model.predict(image)\n",
    "    print('\\n')    \n",
    "    # Здесь можно добавить проверку на качество предсказания или ещё что-то, но пока ее нет\n",
    "    results.append(image_path)\n",
    "    # Закрываем картинку\n",
    "    image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea5cdba1-8f76-4268-9d9d-f4d640a2b586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(results) # это проверка для самой себя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376a453-ea8f-4519-9bce-ffdee94fdd31",
   "metadata": {},
   "source": [
    "## Импортируем нужные библиотеки и зависимости для бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cc4475b5-4c67-4bb3-83ec-82a090ea2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytelegrambotapi in d:\\anaconda\\lib\\site-packages (4.25.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from pytelegrambotapi) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->pytelegrambotapi) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->pytelegrambotapi) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->pytelegrambotapi) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->pytelegrambotapi) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytelegrambotapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8d31c0e4-fed2-46de-a022-bc856fa02502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-telegram-bot in d:\\anaconda\\lib\\site-packages (21.9)\n",
      "Requirement already satisfied: httpx~=0.27 in d:\\anaconda\\lib\\site-packages (from python-telegram-bot) (0.27.2)\n",
      "Requirement already satisfied: anyio in d:\\anaconda\\lib\\site-packages (from httpx~=0.27->python-telegram-bot) (4.2.0)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\lib\\site-packages (from httpx~=0.27->python-telegram-bot) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\lib\\site-packages (from httpx~=0.27->python-telegram-bot) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\anaconda\\lib\\site-packages (from httpx~=0.27->python-telegram-bot) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\lib\\site-packages (from httpx~=0.27->python-telegram-bot) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-telegram-bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e2fc111f-10a9-48ea-a5c1-59a49029e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "from telebot import types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d803c-1be7-48a1-8f87-a9277412c341",
   "metadata": {},
   "source": [
    "## Собственно инициализация бота, токен записан в отдельном файле token.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ced10dca-673f-4b41-ae39-02b828776363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the token\n",
    "with open('token.txt', 'r') as file:\n",
    "    token = file.read().strip()\n",
    "\n",
    "# our bot init\n",
    "bot = telebot.TeleBot(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46255b92-9564-4442-8e8b-edf035186424",
   "metadata": {},
   "source": [
    "Очень простой вариант ответа на сообщения пользователя, чтобы было. \n",
    "\n",
    "Пишем отправку сообщений, картинка и текст - обнаружен маломобильный пользователь. В будущем здесь добавить бы в сообщение номер камеры, на которой был замечен человек, или место, где человек находится. Ну и адекватно сделать оповещение, пока что оно костыльно сделано"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19c5a1d1-bf26-4f85-91e3-c44570198cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(content_types=['text'])\n",
    "def get_text_messages(message):\n",
    "    chat_id = message.chat.id\n",
    "    if message.text in [\"ок\", \"Ок\", \"ОК\", \"оК\"]:\n",
    "        bot.send_message(chat_id, \"Отлично, ответ получен.\")\n",
    "    elif message.text in [\"привет\", \"ПРивет\", \"Привет\", \"ПРИВЕТ\"]:\n",
    "        bot.send_message(chat_id, \"Привет! Я бот, оповещающий о наличии маломобильных людей на территории больницы.\")\n",
    "    elif message.text == \"есть новости\":\n",
    "        bot.send_photo(chat_id, photo=open(results[3], 'rb'), caption='Обнаружен маломобильный пользователь')\n",
    "    elif message.text == \"/help\":\n",
    "        bot.send_message(chat_id, \"Напиши привет\")\n",
    "    elif message.text == \"/start\":\n",
    "        bot.send_message(chat_id, \"Привет, новый пользователь! Я бот, оповещающий о наличии маломобильных людей на территории больницы.\")\n",
    "    else:\n",
    "        bot.send_message(chat_id, \"Я тебя не понимаю. Напиши /help.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852d131-212d-47b8-b634-ea5adc19552e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2e05fd6-1ba7-4136-ada9-1f0d3d0409c4",
   "metadata": {},
   "source": [
    "## Следующая ячейка запустит бота @low_mob_alert_bot в телеграмме\n",
    "\n",
    "Бот не остановится, пока пользователь специально не прервет работу ядра.\n",
    "Пожалуйста, осторожнее с этим куском кода. \n",
    "Раскомментируйте его перед запуском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e1cde7c-4249-4c6a-b872-f52a31b7dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bot.polling(non_stop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
